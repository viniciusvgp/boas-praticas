# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+STARTUP: overview indent
#+LANGUAGE: pt_BR
#+OPTIONS:   toc:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+TITLE:     Realização de Experimentos Computacionais
#+AUTHOR:    Lucas Mello Schnorr, Vinícius Garcia Pinto
#+EMAIL:     {schnorr, vgpinto}@inf.ufrgs.br

# Reserva de nós (SLURM)
# Coleta de dados (bash)

* #2.0 Passos iniciais

Execute os tutoriais precedentes nesta série:
- [[./0_Programa_Teste.org][#0 (Programa Teste)]]
- [[./1_Ferramentas.org][#1 (Ferramentas)]]

Lembre-se
1. Todos os comandos devem ser executados no diretório SEUNOME
2. Existem dois tipos de tarefas
   - *Local*: pode ser feito na máquina do laboratório
   - *Remota*: deve ser feita no parque computacional

* #2.1 Local: Definição do Projeto Experimental

Vamos utilizar o pacote ~DoE.base~ ([[https://cran.r-project.org/web/packages/DoE.base/][descrição mais detalhada]]) da
linguagem ~R~ para gerar um projeto experimental fatorial completo
combinando os fatores a serem analisados.  Como o objetivo nesta série
de tutorial é analisar o tempo de execução e speedup em função da
quantidade de processos e dois tamanhos de problema, definimos dois
fatores: /processes/ e /size/. Testaremos três quantidades de processos:
2, 10 e 20, e dois tamanhos 300 e 400, para um total de 6
combinações possíveis, com três replicações cada.

O comando =set.seed(0)= (veja abaixo) é utilizado para fixar uma ordem
aleatória, permitindo a geração do mesmo ordenamento da bateria
experimental. O código abaixo pode ser executado no interpretador =R=
com o pacote =DoE.base= instalado.

#+begin_src R :results output :exports both :session *R* :eval no-export
library(DoE.base)
set.seed(0)
btmz_erad <- fac.design(factor.names = list(
                                size = c(300, 400),
                                processes = c(2, 10, 20)),
               replications=3, 
               randomize=TRUE)
print(btmz_erad)
#+end_src

#+RESULTS:
#+begin_example

creating full factorial with 6 runs ...

   run.no run.no.std.rp size processes Blocks
1       1           6.1  400        20     .1
2       2           2.1  400         2     .1
3       3           5.1  300        20     .1
4       4           4.1  400        10     .1
5       5           3.1  300        10     .1
6       6           1.1  300         2     .1
7       7           6.2  400        20     .2
8       8           5.2  300        20     .2
9       9           3.2  300        10     .2
10     10           2.2  400         2     .2
11     11           1.2  300         2     .2
12     12           4.2  400        10     .2
13     13           2.3  400         2     .3
14     14           4.3  400        10     .3
15     15           6.3  400        20     .3
16     16           3.3  300        10     .3
17     17           1.3  300         2     .3
18     18           5.3  300        20     .3
class=design, type= full factorial 
NOTE: columns run.no and run.no.std.rp  are annotation, 
 not part of the data frame
#+end_example

A função ~fac.design~ gerou uma sequência aleatória de combinações
que serão executadas para que possamos avaliar a influência de cada
fator no desempenho da aplicação. Exportaremos o projeto gerado para
um arquivo ~CSV~ que deverá ser registrado juntamente com os /logs/
contendo os resultados brutos do experimento. 

#+begin_src R :results output :exports both :session *R* :eval no-export
export.design(btmz_erad,
              filename = "projeto-experimental",
              type = "csv",
              replace = TRUE
              )
#+end_src

#+RESULTS:

Vejamos o conteúdo do arquivo CSV criado:

#+begin_src shell :results output :exports both :eval no-export
cat projeto-experimental.csv
#+end_src

#+RESULTS:
#+begin_example
"name","run.no.in.std.order","run.no","run.no.std.rp","size","processes","Blocks"
"1","6",1,"6.1","400","20",".1"
"2","2",2,"2.1","400","2",".1"
"3","5",3,"5.1","300","20",".1"
"4","4",4,"4.1","400","10",".1"
"5","3",5,"3.1","300","10",".1"
"6","1",6,"1.1","300","2",".1"
"7","6",7,"6.2","400","20",".2"
"8","5",8,"5.2","300","20",".2"
"9","3",9,"3.2","300","10",".2"
"10","2",10,"2.2","400","2",".2"
"11","1",11,"1.2","300","2",".2"
"12","4",12,"4.2","400","10",".2"
"13","2",13,"2.3","400","2",".3"
"14","4",14,"4.3","400","10",".3"
"15","6",15,"6.3","400","20",".3"
"16","3",16,"3.3","300","10",".3"
"17","1",17,"1.3","300","2",".3"
"18","5",18,"5.3","300","20",".3"
#+end_example

Para facilitar o processo, este arquivo [[./projeto-experimental.csv][está registrado aqui]], e pode
ser baixado no parque computacional da seguinte forma:

#+begin_src shell :results output
cd ~/SEUNOME
wget https://gitlab.com/schnorr/erad19/raw/master/projeto-experimental.csv
#+end_src

* #2.2 Remote: Script de execução do projeto

Acessaremos a plataforma =PCAD= do GPPD/INF-UFRGS para execução de
experimentos de demonstração. Ilustraremos, no exemplo abaixo, um
/script/ para execução não-interativa da aplicação. Para efeitos de
simplificação, foi gerado previamente um projeto experimental (arquivo
~projeto-experimental.csv~). Veja passo #2.1 para gerá-lo.

Vamos revisar o /script/ que automatiza a execução do experimento.

#+begin_src shell :tangle executa-projeto.slurm
#!/bin/bash
#SBATCH --job-name=exp0
#SBATCH --time=01:00:00
#SBATCH --nodes=2
#SBATCH --tasks-per-node=10
#SBATCH --ntasks=20
#SBATCH --partition=tupi

# Diretório de base (atualize para seu caso
export BASE=~/SEUNOME/

# Ingressar no diretório de base
pushd $BASE

# Criar um diretório para conter todos os resultados
rm -rf $SLURM_JOB_NAME
mkdir -p $SLURM_JOB_NAME
pushd $SLURM_JOB_NAME

# Define o Machine File necessário para MPI
MACHINEFILE="nodes.$SLURM_JOB_ID"
srun $SRUN_PACK /bin/hostname | sort -n | awk "{print $2}" > $MACHINEFILE

# Verificar se projeto experimental é fornecido
PROJETO=$BASE/projeto-experimental.csv
if [[ -f $PROJETO ]]; then
  echo "O projeto experimental é o seguinte"
  cat $PROJETO | sed -e "s/^/PROJETO|/"
  # Salva o projeto no diretório corrente (da saída)
  cp $PROJETO .
else
  echo "Arquivo $PROJETO está faltando."
  exit
fi

# Verificar se programa é fornecido
PROGRAMA=$BASE/mpi_mm.c
if [[ -f $PROGRAMA ]]; then
  echo "O programa é o seguinte"
  cat $PROGRAMA | sed -e "s/^/PROGRAMA|/"
  # Salva o programa no diretório corrente (da saída)
  cp $PROGRAMA .
else
  echo "Arquivo $PROGRAMA está faltando."
  exit
fi

# Ler o projeto experimental, e para cada experimento
tail -n +2 $PROJETO |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 size processes Blocks
do
    # Limpar valores
    export name=$(echo $name | sed "s/\"//g")
    export processes=$(echo $processes | sed "s/\"//g")
    export size=$(echo $size | sed "s/\"//g")

    # Definir uma chave única
    KEY="$name-$processes-$size"

    # Usar a versão apropriada de MPI
    MPICC=mpicc   #$(spack location -i openmpi@$mpi)/bin/mpicc
    MPIRUN=mpirun #$(spack location -i openmpi@$mpi)/bin/mpirun

    # Altera o código fonte com o tamanho do problema
    sed -i -e "s/#define NRA \(.*\)$/#define NRA $size/" \
           -e "s/#define NCA \(.*\)$/#define NCA $size/" $PROGRAMA

    # Compilar o programa com a versão apropriada
    $MPICC $PROGRAMA -o mpi_mm
    ls -l mpi_mm
    ldd mpi_mm
    sync

    echo $KEY

    # Prepara comando de execução
    runline=""
    runline+="mpirun -np $processes "

    runline+=" -machinefile $MACHINEFILE "
#    runline+="--mca oob_tcp_if_include 192.168.30.0/24 --mca btl_tcp_if_include 192.168.30.0/24 "
    runline+="./mpi_mm "
    runline+="> ${KEY}.log"

    # 3.3 Executar o experimento
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done

cp $BASE/slurm-$SLURM_JOB_ID.out .

exit


# 

#srun -l cd $SCRATCH
#srun -l rm -rf $SCRATCH/erad-tuto
#srun -l mkdir -p $SCRATCH/erad-tuto
#srun -l cd erad-tuto
#cd $SCRATCH/erad-tuto
#srun -l cp ~/disable_hyperthreading.sh ./
#srun -l cp ~/hyperthreading.sh ./
#srun -l cp ~/disable_turboboost.sh ./
#srun -l cp ~/detect_acpidriver.sh ./
#srun -l cp ~/get_info.sh ./
#srun -l cp ~/slurm-script.sh ./ 
#srun -l chmod +x *sh

# 1. Controle inicial dos nós computacionais (HW e SW)


#  Disable Turboboost/Hyperthreading
#srun -l ./disable_turboboost.sh
#srun -l ./disable_hyperthreading.sh

# 2. Registro das condições iniciais
#srun -l ./get_info.sh GetInfoInicio-$HOSTNAME.org



# 4. Centralizar os dados em um único diretório
mkdir -p exp-$HOSTNAME-`date "+%d%b%G-%H%M%S"`
mv exp-log-btmz* exp-$HOSTNAME-`date "+%d%b%G-%H%M%S"`/

# 5. Arquivar este script e logs junto com os dados
cp btmz-exec-order.csv exp-$HOSTNAME-`date "+%d%b%G-%H%M%S"`/
cp *sh  exp-$HOSTNAME-`date "+%d%b%G-%H%M%S"`/

# Copy scratch 
cp -r $SCRATCH ~/$SCRATCH-$HOSTNAME

#+end_src

#+RESULTS:

* Introdução ao Slurm                                              :noexport:

Neste tutorial usaremos o gerenciador de filas =Slurm= ([[https://slurm.schedmd.com][site oficial]]). O
~Slurm~ é uma ferramente /open-source/ que permite a execução de /jobs/
interativos ou não-interativos.

O comando ~salloc~ abaixo exemplifica como pode ser realizada
solicitação de um /job/ interativo nomeado =MeuJobErad= na partição de
nome ~hype~, pelo período de 1 hora e 30 minutos.

#+begin_src shell :results output :exports both
salloc -p hype -J MeuJobErad -t 00:10:00
#+end_src

Quando a solicitação for atendida (o que pode ocorrer imediatamente
caso a plataforma esteja ociosa), o usuário estará apto a acessar a
máquina requisitada via ~ssh~ ou a executar diretamente sua aplicação
por meio do comando ~srun~.

Para /jobs/ não-interativos (recomendados, pela automatização possível)
deve-se utilizar o comando ~sbatch~. Neste caso, o usuário fornecerá um
/script/ contendo todos os passos para realizar o experimento na
plataforma desejada. /Jobs/ não-interativos são bastante úteis quando a
plataforma é compartilhada entre muitos usuários estando
frequentemente ocupada e com uma significativa fila de espera. Neste
cenário, o /job/ do usuário poderá executar a qualquer momento após a
submissão, podendo ser iniciado em alguns segundos ou até mesmo após
vários dias da submissão. A política de filas não necessariamente é
/FIFO (First-In First-Out)/ pois alguns usuários podem ter preferência
sobre outros, por exemplo, contas internas /vs/ externas, preferência ao
proprietário/financiador da plataforma, preferência a equipe de
manutenção/suporte, etc.

Um ~job~ termina após uma das seguintes condições (a que occorer
primeiro): a execução da última linha do /script/ fornecido ou após o
término do tempo de processamento solicitado na reserva. Além destes
dois casos bases, o /job/ também pode ser encerrado por pedido do
usuário através do comando ~scancel~ ou por situações inesperadas como
problemas na plataforma ou comandos do administrador. 

O código abaixo ilustra um exemplo de /script/ a ser submetido com o
comando ~sbatch script-exemplo.sh~ ([[./script-exemplo.sh][veja o arquivo aqui]]). Este /script/
exemplo solicita a reserva de 2 nós na plataforma =hype= pelo período
máximo de 40 minutos. As saídas padrão (/stdout/) e de erro (/stdin/)
serão redirecionadas para arquivos nomeados com o identificador do
/job/.

#+begin_src shell :results output :exports both :tangle script-exemplo.sh :eval no-exoort
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --partition=hype
#SBATCH --time=00:20:00
#SBATCH --output=%x_%j.out
#SBATCH --error=%x_%j.err

# Comandos para execução do experimento 

#+end_src

* Execução de uma aplicação paralela exemplo                       :noexport:
** Obtenção e Configuração da Aplicação

Utilizaremos como exemplo uma aplicação da versão /Multi-Zone do
conjunto de /benchmarks/ do /NAS Parallel Benchmarks/ (NPB, [[https://www.nas.nasa.gov/publications/npb.html][mais
informações aqui]]), em específico a aplicação ~BT~ (/Block Tri-diagonal/)
com as classes W (execução local), A e D (execução no =PCAD=).  As
classes nos /benchmarks/ NAS representam diferentes tamanhos de entrada
do problema. A aplicação ~BT~ resolve um sistema sintético de equações
diferenciais parciais não lineares.  A versão /Multi-Zone/ é a variante
do NPB com implementações híbridas combinando MPI e OpenMP. Neste
contexto, escolhemos a aplicação ~BT-MZ~ para este tutorial pois é a que
apresenta maiores desafios quanto ao balanceamento de carga em
comparação com os outros /benchmarks/ da variante /Multi-Zone/.

#+BEGIN_COMMENT Vinícius
- [x] Completar aqui com detalhes do BT em comparação com outros
      benchmarks Explicar o MZ (multi-zone)
#+END_COMMENT

#+BEGIN_COMMENT Lucas
- [x] Demonstrar como fazer para usar um MPI instalado com o spack
#+END_COMMENT

#+begin_src shell :results output :exports both :eval no-export
wget https://www.nas.nasa.gov/assets/npb/NPB3.4-MZ.tar.gz
tar -xf NPB3.4-MZ.tar.gz
cd NPB3.4-MZ/NPB3.4-MZ-MPI
cp config/NAS.samples/make.def.gcc_mpich config/make.def
make bt-mz CLASS=A
make bt-mz CLASS=W
#+end_src

A etapa de compilação dos /benchmarks/ do NAS utiliza arquivos de
configuração, como o ~config/make.def~ dos comandos acima, para indicar
quais compiladores e bibliotecas devem ser empregados na construção
dos binários. Para utilizar compiladores e bibliotecas que não estão
no ~PATH~ padrão, basta editar este arquivo. Tal estratégia pode ser
usada para construção de binários utilizando uma implementação ~MPI~
instalada com o ~Spack~ conforme ilustrado na etapa anterior deste
tutorial. 

** Execução dos Experimentos (manualmente)

Faremos a execução dos experimentos na ordem definida no projeto
experimental. 

#+begin_src shell :results output :exports code :eval no-export
tail -n +2 btmz-exec-order.csv |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 threads processes class Blocks
do
    # OpenMP threads
    runline="OMP_NUM_THREADS=$threads "
    # MPI processes
    runline+="mpirun -np $processes "
    # Binary
    runline+="bin/bt-mz.$class.x "
    # Log
    runline+="> btmz-$runno-$threads-$processes-$class.log"
 
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done 
#+end_src

** Execução Não-Interativa de Experimentos com /Slurm/ na plataforma =PCAD=
* Controle e Registro
Os /scripts/ a seguir contêm os comandos necessários para controle e
registro de informações da plataforma. É conveniente manter os dados
coletados juntamente com os /logs/ dos experimentos de forma a facilitar
a análise posterior dos resultados. 

** Desabilitar /Turboboost/ (Processadores Intel)
#+begin_src shell :results output :exports code :eval no-export :tangle disable_turboboost.sh
#!/bin/bash
DIR=$(dirname $0)

if [ `lsmod | grep msr | wc -l` -ne 1 ]; then
    echo "The =msr= module is not loaded. It should be."
    exit 1;
fi

# Get the list of online cores
ONLINECPUS=$(for CPU in $(find /sys/devices/system/cpu/ | grep -v cpu0 | grep cpu[0-9]*$); do [[ $(cat $CPU/online) -eq 1 ]] && echo $CPU; done | grep cpu[0-9]*$ | sed 's/.*cpu//')

# Enable
for PU in ${ONLINECPUS}; do
    sudo zsh -c "/usr/sbin/wrmsr -p${PU} 0x1a0 0x850089"
done

# Disable & Check
for PU in ${ONLINECPUS}; do
    echo "Disabling turbo boost mode for PU $PU."
    sudo zsh -c "/usr/sbin/wrmsr -p${PU} 0x1a0 0x4000850089"
    TURBOBOOST=$(sudo zsh -c "/usr/sbin/rdmsr -p${PU} 0x1a0 -f 38:38")
    if [[ "0" = $TURBOBOOST ]]; then
       echo "Failed to disable turbo boost for PU number $cpu. Aborting."
       exit 1
    fi
done
#+end_src

** Desabilitar /Hyperthreading/ (Processadores Intel)
#+begin_src shell :results output :exports code :eval no-export :tangle disable_hyperthreading.sh
#!/bin/bash
DIR=$(dirname $0)

#First, enable all cores
for PU in `find /sys/devices/system/cpu/ |grep cpu[0-9]*$`; do
   echo "Enabling $PU now."
    sudo zsh -c "echo 1 > ${PU}/online"
done

HYPERTHREADING=`$DIR/hyperthreading.sh | grep -e "Hyperthreading is ON" | wc -l`
if [ $HYPERTHREADING -eq 0 ]; then
   echo "Hyperthreading is OFF, so disabling is not necessary."
   exit
else
    echo "Hyperthreading is ON."
fi
echo "The number of PUs now is $(hwloc-ls  --only PU | wc -l)."
echo "I will disable hyperthreading now."
# Disable hyperthreading
# Only run this if you are sure
# - Hyperthreading is enabled
# - Each physical core has two processing units (PU)
# - hwloc-ls is installed and reports two PU per physical core
for PU in `hwloc-ls --only PU | cat -n | grep -e "[[:space:]]*[0-9]*[02468][[:space:]]*PU" | sed -e "s/^[^(]*(P#\\([0-9]*\))/\1/"`; do
   echo "Disabling PU $PU now."
   sudo zsh -c "echo 0 > /sys/devices/system/cpu/cpu${PU}/online"
done
echo "The number of PUs now is $(hwloc-ls  --only PU | wc -l)."

#+end_src

#+begin_src shell :results output :exports code :eval no-export :tangle hyperthreading.sh
#!/bin/bash
CPUFILE=/proc/cpuinfo
test -f $CPUFILE || exit 1
NUMPHYCPU=`grep "physical id" $CPUFILE | sort -u | wc -l`
NUMLOGCORE=`grep "processor" $CPUFILE | wc -l`
NUMPHYCORE=`grep "core id" $CPUFILE | sort -u | wc -l`
TOTALNUMPHYCORE=$(echo "$NUMPHYCPU * $NUMPHYCORE" | bc)
MODEL=`grep "model name" $CPUFILE | sort -u | cut -d : -f 2- | sed "s/^[[:space:]]*//"`
echo "This system has $NUMPHYCPU CPUs, of model \"$MODEL\"."
echo "Each physical CPU is equipped with $NUMPHYCORE physical cores (total is $TOTALNUMPHYCORE)."
if [ $TOTALNUMPHYCORE -ne $NUMLOGCORE ]; then
   echo "Hyperthreading is ON. So, there are $NUMLOGCORE logical cores."
else
   echo "Hyperthreading is OFF."
fi
exit
#+end_src

** Detectar Driver ACPI
#+begin_src shell :results output :exports code :eval no-export :tangle detect_acpidriver.sh
#!/bin/bash
DIR=$(dirname $0)

function usage()
{
    echo "Input: number of CPUs to be used"
    echo "Output: core identifiers (NUMA-aware)"
    echo "$0 <ncpus>";
}

PRESENT=$(cpufreq-info | grep driver | uniq | grep acpi-cpufreq | wc -l)
if [ $PRESENT -ne 1 ]; then
    exit 1;
fi

exit 0

#+end_src

** Registro de Informações do Plataforma
#+begin_src shell :results output :exports code :tangle get_info.sh :eval no-export
#!/bin/bash
# Script for to get machine information before doing the experiment

set +e # Don't fail fast since some information is maybe not available

title="Experiment results"
inputfile=""
host="$(hostname | sed 's/[0-9]*//g' | cut -d'.' -f1)"
help_script()
{
    cat << EOF
Usage: $0 [options] outputfile.org

Script for to get machine information before doing the experiment

OPTIONS:
   -h      Show this message
   -t      Title of the output file
EOF
}
# Parsing options
while getopts "t:s:i:h" opt; do
    case $opt in
	t)
	    title="$OPTARG"
	    ;;
	h)
	    help_script
	    exit 4
	    ;;
	\?)
	    echo "Invalid option: -$OPTARG"
	    help_script
	    exit 3
	    ;;
    esac
done

shift $((OPTIND - 1))
filedat=$1
if [[ $# != 1 ]]; then
    echo 'ERROR!'
    help_script
    exit 2
fi

##################################################
# Preambule of the output file
echo "#+TITLE: $title" >> $filedat
echo "#+DATE: $(eval date)" >> $filedat
echo "#+AUTHOR: $(eval whoami)" >> $filedat
echo "#+MACHINE: $(eval hostname)" >> $filedat
echo "#+FILE: $(eval basename $filedat)" >> $filedat
if [[ -n "$inputfile" ]]; 
then
    echo "#+INPUTFILE: $inputfile" >> $filedat
fi
echo " " >> $filedat 

##################################################
# Collecting metadata
echo "* MACHINE INFO:" >> $filedat

echo "** PEOPLE LOGGED WHEN EXPERIMENT STARTED:" >> $filedat
who >> $filedat
echo "############################################" >> $filedat

echo "** ENVIRONMENT VARIABLES:" >> $filedat
env >> $filedat
echo "############################################" >> $filedat

echo "** HOSTNAME:" >> $filedat
hostname >> $filedat
echo "############################################" >> $filedat

if [[ -n $(command -v lstopo) ]];
then
    echo "** MEMORY HIERARCHY:" >> $filedat
    lstopo --of console >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /proc/cpuinfo ];
then
    echo "** CPU INFO:" >> $filedat
    cat /proc/cpuinfo >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor ];
then
    echo "** CPU GOVERNOR:" >> $filedat
    ONLINECPUS=$(for CPU in $(find /sys/devices/system/cpu/ | grep cpu[0-9]*$); do [[ $(cat $CPU/online) -eq 1 ]] && echo $CPU; done | grep cpu[0-9]*$ | sed 's/.*cpu//')
    for PU in ${ONLINECPUS}; do
	     echo -n "CPU frequency for cpu${PU}: " >> $filedat
       cat /sys/devices/system/cpu/cpu${PU}/cpufreq/scaling_governor >> $filedat
    done
    echo "############################################" >> $filedat
fi

if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq ];
then
    echo "** CPU FREQUENCY:" >> $filedat
    ONLINECPUS=$(for CPU in $(find /sys/devices/system/cpu/ | grep cpu[0-9]*$); do [[ $(cat $CPU/online) -eq 1 ]] && echo $CPU; done | grep cpu[0-9]*$ | sed 's/.*cpu//')
    for PU in ${ONLINECPUS}; do
	     echo -n "CPU frequency for cpu${PU}: " >> $filedat
	     cat /sys/devices/system/cpu/cpu${PU}/cpufreq/scaling_cur_freq >> $filedat
    done
    echo "############################################" >> $filedat
fi

if [ -f /usr/bin/cpufreq-info ];
then
    echo "** CPUFREQ_INFO" >> $filedat
    cpufreq-info >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /usr/bin/lspci ];
then
    echo "** LSPCI" >> $filedat
    lspci >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /usr/bin/ompi_info ];
then
    echo "** OMPI_INFO" >> $filedat
    ompi_info --all >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /sbin/ifconfig ];
then
    echo "** IFCONFIG" >> $filedat
    /sbin/ifconfig >> $filedat
    echo "############################################" >> $filedat
fi

if [[ -n $(command -v nvidia-smi) ]];
then
    echo "** GPU INFO FROM NVIDIA-SMI:" >> $filedat
    nvidia-smi -q >> $filedat
    echo "############################################" >> $filedat
fi 

if [ -f /proc/version ];
then
    echo "** LINUX AND GCC VERSIONS:" >> $filedat
    cat /proc/version >> $filedat
    echo "############################################" >> $filedat
fi

if [[ -n $(command -v module) ]];
then
    echo "** MODULES:" >> $filedat
    module list 2>> $filedat
    echo "############################################" >> $filedat
fi

echo "** TCP PARAMETERS" >> $filedat
FILES="/proc/sys/net/core/rmem_max \
/proc/sys/net/core/wmem_max \
/proc/sys/net/core/rmem_default \
/proc/sys/net/core/wmem_default \
/proc/sys/net/core/netdev_max_backlog \
/proc/sys/net/ipv4/tcp_rmem \
/proc/sys/net/ipv4/tcp_wmem \
/proc/sys/net/ipv4/tcp_mem"

for FILE in $FILES; do
    echo "cat $FILE"
    cat $FILE
done >> $filedat

#+end_src

* Local Variables                                                  :noexport:
# Local Variables:
# eval: (ox-extras-activate '(ignore-headlines))
# eval: (setq org-latex-listings t)
# eval: (setq org-latex-packages-alist '(("" "listings")))
# eval: (setq org-latex-packages-alist '(("" "listingsutf8")))
# eval: (setq ispell-local-dictionary "brasileiro")
# eval: (flyspell-mode t)
# End:
