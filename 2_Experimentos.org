# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+STARTUP: overview indent
#+LANGUAGE: pt_BR
#+OPTIONS:   toc:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+TITLE:     Realização de Experimentos Computacionais
#+AUTHOR:    Lucas Mello Schnorr, Vinícius Garcia Pinto
#+EMAIL:     {schnorr, vgpinto}@inf.ufrgs.br

# Reserva de nós (SLURM)
# Coleta de dados (bash)

* Introdução ao Slurm

Neste tutorial usaremos o gerenciador de filas =Slurm= ([[https://slurm.schedmd.com][site oficial]]). O
~Slurm~ é uma ferramente /open-source/ que permite a execução de /jobs/
interativos ou não-interativos.

O comando ~salloc~ abaixo exemplifica como pode ser realizada
solicitação de um /job/ interativo nomeado =MeuJobErad= na partição de
nome ~hype~, pelo período de 1 hora e 30 minutos.

#+begin_src shell :results output :exports both
salloc -p hype -J MeuJobErad -t 01:30:00
#+end_src

Quando a solicitação for atendida (o que pode ocorrer imediatamente
caso a plataforma esteja ociosa), o usuário estará apto a acessar a
máquina requisitada via ~ssh~ ou a executar diretamente sua aplicação
por meio do comando ~srun~.

Para /jobs/ não-interativos (recomendados, pela automatização possível)
deve-se utilizar o comando ~sbatch~. Neste caso, o usuário fornecerá um
/script/ contendo todos os passos para realizar o experimento na
plataforma desejada. /Jobs/ não-interativos são bastante úteis quando a
plataforma é compartilhada entre muitos usuários estando
frequentemente ocupada e com uma significativa fila de espera. Neste
cenário, o /job/ do usuário poderá executar a qualquer momento após a
submissão, podendo ser iniciado em alguns segundos ou até mesmo após
vários dias da submissão. A política de filas não necessariamente é
/FIFO (First-In First-Out)/ pois alguns usuários podem ter preferência
sobre outros, por exemplo, contas internas /vs/ externas, preferência ao
proprietário/financiador da plataforma, preferência a equipe de
manutenção/suporte, etc.

Um ~job~ termina após uma das seguintes condições (a que occorer
primeiro): a execução da última linha do /script/ fornecido ou após o
término do tempo de processamento solicitado na reserva. Além destes
dois casos bases, o /job/ também pode ser encerrado por pedido do
usuário através do comando ~scancel~ ou por situações inesperadas como
problemas na plataforma ou comandos do administrador. 

O código abaixo ilustra um exemplo de /script/ a ser submetido com o
comando ~sbatch script-exemplo.sh~ ([[./script-exemplo.sh][veja o arquivo aqui]]). Este /script/
exemplo solicita a reserva de 2 nós na plataforma =hype= pelo período
máximo de 40 minutos. As saídas padrão (/stdout/) e de erro (/stdin/)
serão redirecionadas para arquivos nomeados com o identificador do
/job/.

#+begin_src shell :results output :exports both :tangle script-exemplo.sh :eval no-exoort
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --partition=hype
#SBATCH --time=00:40:00
#SBATCH --output=%x_%j.out
#SBATCH --error=%x_%j.err

# Comandos para execução do experimento 

#+end_src

* Execução de uma aplicação paralelo exemplo
** Obtenção e Configuração da Aplicação

Utilizaremos como exemplo uma aplicação da versão /Multi-Zone do
conjunto de /benchmarks/ do /NAS Parallel Benchmarks/ (NPB, [[https://www.nas.nasa.gov/publications/npb.html][mais
informações aqui]]), em específico a aplicação ~BT~ (/Block Tri-diagonal/)
com as classes W (execução local), A e D (execução no =PCAD=).  As
classes nos /benchmarks/ NAS representam diferentes tamanhos de entrada
do problema. A aplicação ~BT~ resolve um sistema sintético de equações
diferenciais parciais não lineares.  A versão /Multi-Zone/ é a variante
do NPB com implementações híbridas combinando MPI e OpenMP. Neste
contexto, escolhemos a aplicação ~BT-MZ~ para este tutorial pois é a que
apresenta maiores desafios quanto ao balanceamento de carga em
comparação com os outros /benchmarks/ da variante /Multi-Zone/.

#+BEGIN_COMMENT Vinícius
- [x] Completar aqui com detalhes do BT em comparação com outros
      benchmarks Explicar o MZ (multi-zone)
#+END_COMMENT

#+BEGIN_COMMENT Lucas
- [x] Demonstrar como fazer para usar um MPI instalado com o spack
#+END_COMMENT

#+begin_src shell :results output :exports both :eval no-export
wget https://www.nas.nasa.gov/assets/npb/NPB3.4-MZ.tar.gz
tar -xf NPB3.4-MZ.tar.gz
cd NPB3.4-MZ/NPB3.4-MZ-MPI
cp config/NAS.samples/make.def.gcc_mpich config/make.def
make bt-mz CLASS=A
make bt-mz CLASS=W
#+end_src

A etapa de compilação dos /benchmarks/ do NAS utiliza arquivos de
configuração, como o ~config/make.def~ dos comandos acima, para indicar
quais compiladores e bibliotecas devem ser empregados na construção
dos binários. Para utilizar compiladores e bibliotecas que não estão
no ~PATH~ padrão, basta editar este arquivo. Tal estratégia pode ser
usada para construção de binários utilizando uma implementação ~MPI~
instalada com o ~Spack~ conforme ilustrado na etapa anterior deste
tutorial. 


** Projeto Experimental

Após a instalação e configuração da aplicação, vamos utilizar o pacote
~DoE.base~ ([[https://cran.r-project.org/web/packages/DoE.base/][descrição mais detalhada]]) da linguagem ~R~ para gerar um
projeto experimental completo combinando os fatores a serem
analisados. Neste exemplo, os fatores serão o número de /threads/, o
número de processos (/processes/) e a classe do problema (/class/). O
comando =set.seed(0)= é utilizado para fixar uma ordem aleatória,
permitindo maior reprodutibilidade da ordem da bateria experimetal.

#+begin_src R :results output :exports both :session *R* :eval no-export
library("DoE.base")
library("dplyr")

set.seed(0)

btmz_erad <-
    fac.design(factor.names=
                   list(threads   = c(1, 2), 
                        processes = c(1, 2), 
                        class     = c("W", "A")),
               replications=2, 
               randomize=TRUE
               )

print(btmz_erad)
#+end_src

#+RESULTS:
#+begin_example

creating full factorial with 8 runs ...

   run.no run.no.std.rp threads processes class Blocks
1       1           6.1       2         1     A     .1
2       2           2.1       2         1     W     .1
3       3           5.1       1         1     A     .1
4       4           1.1       1         1     W     .1
5       5           7.1       1         2     A     .1
6       6           8.1       2         2     A     .1
7       7           3.1       1         2     W     .1
8       8           4.1       2         2     W     .1
9       9           2.2       2         1     W     .2
10     10           7.2       1         2     A     .2
11     11           8.2       2         2     A     .2
12     12           1.2       1         1     W     .2
13     13           6.2       2         1     A     .2
14     14           4.2       2         2     W     .2
15     15           3.2       1         2     W     .2
16     16           5.2       1         1     A     .2
class=design, type= full factorial 
NOTE: columns run.no and run.no.std.rp  are annotation, 
 not part of the data frame
#+end_example

A função ~fac.design~ gerou uma sequência aleatória de combinações
que serão executadas para que possamos avaliar a influência de cada
fator no desempenho da aplicação. Exportaremos o projeto gerado para
um arquivo ~csv~ que deverá ser registrado juntamente com os /logs/
contendo os resultados brutos do experimento. 

#+begin_src R :results output :exports both :session *R* :eval no-export
export.design(btmz_erad, 
              filename = "btmz-exec-order",
              type = "csv",
              replace = TRUE
              )
#+end_src

#+RESULTS:

Vejamos o conteúdo do arquivo CSV criado:

#+begin_src shell :results output :exports both :eval no-export
cat btmz-exec-order.csv
#+end_src

#+RESULTS:
#+begin_example
"name","run.no.in.std.order","run.no","run.no.std.rp","threads","processes","class","Blocks"
"1","6",1,"6.1","2","1","A",".1"
"2","2",2,"2.1","2","1","W",".1"
"3","5",3,"5.1","1","1","A",".1"
"4","1",4,"1.1","1","1","W",".1"
"5","7",5,"7.1","1","2","A",".1"
"6","8",6,"8.1","2","2","A",".1"
"7","3",7,"3.1","1","2","W",".1"
"8","4",8,"4.1","2","2","W",".1"
"9","2",9,"2.2","2","1","W",".2"
"10","7",10,"7.2","1","2","A",".2"
"11","8",11,"8.2","2","2","A",".2"
"12","1",12,"1.2","1","1","W",".2"
"13","6",13,"6.2","2","1","A",".2"
"14","4",14,"4.2","2","2","W",".2"
"15","3",15,"3.2","1","2","W",".2"
"16","5",16,"5.2","1","1","A",".2"
#+end_example

** Execução dos Experimentos (manualmente)

Faremos a execução dos experimentos na ordem definida no projeto
experimental. 

#+begin_src shell :results output :exports code :eval no-export
tail -n +2 btmz-exec-order.csv |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 threads processes class Blocks
do
    # OpenMP threads
    runline="OMP_NUM_THREADS=$threads "
    # MPI processes
    runline+="mpirun -np $processes "
    # Binary
    runline+="bin/bt-mz.$class.x "
    # Log
    runline+="> btmz-$runno-$threads-$processes-$class.log"
 
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done 
#+end_src

** Execução Não-Interativa de Experimentos com /Slurm/ na plataforma =PCAD=

Acessaremos a plataforma =PCAD= do GPPD/INF-UFRGS para execução de
experimentos de demonstração. Ilustraremos, no exemplo abaixo, um
/script/ para execução não-interativa da aplicação ~BT-MZ~ do pacote
NPB. Para efeitos de simplificação, foi gerado previamente um projeto
experimental (arquivo ~btmz-exec-order.csv~) considerando informações
sobre os recursos de processamento da plataforma obtidas com o
~hwloc~. Este projeto (arquivo CSV) pode ser regerado com o código
apresentado na seção acima.

#+begin_src shell :results output :exports both :tangle slurm-script.sh :eval no-export
#!/bin/bash
#SBATCH --nodes=2
#SBATCH --time=02:00:00
#SBATCH --partition=hype
#SBATCH --job-name=erad-2019-tutorial

# Working on scratch
cd $SCRATCH
mkdir erad-tuto
cd erad-tuto

# Spack and hwloc
git clone https://github.com/spack/spack.git
cd spack
./bin/spack install hwloc@2.0.2~gl+cairo~cuda+pci
cd ..

# Application
wget https://www.nas.nasa.gov/assets/npb/NPB3.4-MZ.tar.gz
tar -xf NPB3.4-MZ.tar.gz
cd NPB3.4-MZ/NPB3.4-MZ-MPI
cp config/NAS.samples/make.def.gcc_mpich config/make.def
make bt-mz CLASS=A
make bt-mz CLASS=W
cd ../..

# Experiments design (copy) 
cp ~/btmz-exec-order.csv ./

# MPI Machine file
MACHINEFILE="nodes.$SLURM_JOB_ID"
srun -l hostname | sort -n | awk '{print $2}' > $MACHINEFILE

tail -n +2 btmz-exec-order.csv |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 threads processes class Blocks
do
    # OpenMP threads
    runline="OMP_NUM_THREADS=$threads "
    # MPI processes
    runline+="mpirun -np $processes "
    # MPI machine file
    runline+=" -machinefile $MACHINEFILE "
    # Binary
    runline+="bin/bt-mz.$class.x "
    # Log
    runline+="> btmz-$runno-$threads-$processes-$class.log"
 
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done 
# Get info
#+end_src

* Controle e Registro
Os /scripts/ a seguir contêm os comandos necessários para controle e
registro de informações da plataforma. É conveniente manter os dados
coletados juntamente com os /logs/ dos experimentos de forma a facilitar
a análise posterior dos resultados. 

** Desabilitar /Turboboost/ (Processadores Intel)
#+begin_src shell :results output :exports code :eval no-export :tangle disable_turboboost.sh
#!/bin/bash
DIR=$(dirname $0)

if [ `lsmod | grep msr | wc -l` -ne 1 ]; then
    echo "The =msr= module is not loaded. It should be."
    exit 1;
fi

# Get the list of online cores
ONLINECPUS=$(for CPU in $(find /sys/devices/system/cpu/ | grep -v cpu0 | grep cpu[0-9]*$); do [[ $(cat $CPU/online) -eq 1 ]] && echo $CPU; done | grep cpu[0-9]*$ | sed 's/.*cpu//')

# Enable
for PU in ${ONLINECPUS}; do
    sudo zsh -c "/usr/sbin/wrmsr -p${PU} 0x1a0 0x850089"
done

# Disable & Check
for PU in ${ONLINECPUS}; do
    echo "Disabling turbo boost mode for PU $PU."
    sudo zsh -c "/usr/sbin/wrmsr -p${PU} 0x1a0 0x4000850089"
    TURBOBOOST=$(sudo zsh -c "/usr/sbin/rdmsr -p${PU} 0x1a0 -f 38:38")
    if [[ "0" = $TURBOBOOST ]]; then
       echo "Failed to disable turbo boost for PU number $cpu. Aborting."
       exit 1
    fi
done
#+end_src

** Desabilitar /Hyperthreading/ (Processadores Intel)
#+begin_src shell :results output :exports code :eval no-export :tangle disable_hyperthreading.sh
#!/bin/bash
DIR=$(dirname $0)

#First, enable all cores
for PU in `find /sys/devices/system/cpu/ |grep cpu[0-9]*$`; do
   echo "Enabling $PU now."
    sudo zsh -c "echo 1 > ${PU}/online"
done

HYPERTHREADING=`$DIR/hyperthreading.sh | grep -e "Hyperthreading is ON" | wc -l`
if [ $HYPERTHREADING -eq 0 ]; then
   echo "Hyperthreading is OFF, so disabling is not necessary."
   exit
else
    echo "Hyperthreading is ON."
fi
echo "The number of PUs now is $(hwloc-ls  --only PU | wc -l)."
echo "I will disable hyperthreading now."
# Disable hyperthreading
# Only run this if you are sure
# - Hyperthreading is enabled
# - Each physical core has two processing units (PU)
# - hwloc-ls is installed and reports two PU per physical core
for PU in `hwloc-ls --only PU | cat -n | grep -e "[[:space:]]*[0-9]*[02468][[:space:]]*PU" | sed -e "s/^[^(]*(P#\\([0-9]*\))/\1/"`; do
   echo "Disabling PU $PU now."
   sudo zsh -c "echo 0 > /sys/devices/system/cpu/cpu${PU}/online"
done
echo "The number of PUs now is $(hwloc-ls  --only PU | wc -l)."

#+end_src


** Detectar Driver ACPI
#+begin_src shell :results output :exports code :eval no-export :tangle detect_acpidriver.sh
#!/bin/bash
DIR=$(dirname $0)

function usage()
{
    echo "Input: number of CPUs to be used"
    echo "Output: core identifiers (NUMA-aware)"
    echo "$0 <ncpus>";
}

PRESENT=$(cpufreq-info | grep driver | uniq | grep acpi-cpufreq | wc -l)
if [ $PRESENT -ne 1 ]; then
    exit 1;
fi

exit 0

#+end_src


** Registro de Informações do Plataforma
#+begin_src shell :results output :exports code :tangle get_info.sh :eval no-export
#!/bin/bash
# Script for to get machine information before doing the experiment

set +e # Don't fail fast since some information is maybe not available

title="Experiment results"
inputfile=""
host="$(hostname | sed 's/[0-9]*//g' | cut -d'.' -f1)"
help_script()
{
    cat << EOF
Usage: $0 [options] outputfile.org

Script for to get machine information before doing the experiment

OPTIONS:
   -h      Show this message
   -t      Title of the output file
EOF
}
# Parsing options
while getopts "t:s:i:h" opt; do
    case $opt in
	t)
	    title="$OPTARG"
	    ;;
	h)
	    help_script
	    exit 4
	    ;;
	\?)
	    echo "Invalid option: -$OPTARG"
	    help_script
	    exit 3
	    ;;
    esac
done

shift $((OPTIND - 1))
filedat=$1
if [[ $# != 1 ]]; then
    echo 'ERROR!'
    help_script
    exit 2
fi

##################################################
# Preambule of the output file
echo "#+TITLE: $title" >> $filedat
echo "#+DATE: $(eval date)" >> $filedat
echo "#+AUTHOR: $(eval whoami)" >> $filedat
echo "#+MACHINE: $(eval hostname)" >> $filedat
echo "#+FILE: $(eval basename $filedat)" >> $filedat
if [[ -n "$inputfile" ]]; 
then
    echo "#+INPUTFILE: $inputfile" >> $filedat
fi
echo " " >> $filedat 

##################################################
# Collecting metadata
echo "* MACHINE INFO:" >> $filedat

echo "** PEOPLE LOGGED WHEN EXPERIMENT STARTED:" >> $filedat
who >> $filedat
echo "############################################" >> $filedat

echo "** ENVIRONMENT VARIABLES:" >> $filedat
env >> $filedat
echo "############################################" >> $filedat

echo "** HOSTNAME:" >> $filedat
hostname >> $filedat
echo "############################################" >> $filedat

if [[ -n $(command -v lstopo) ]];
then
    echo "** MEMORY HIERARCHY:" >> $filedat
    lstopo --of console >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /proc/cpuinfo ];
then
    echo "** CPU INFO:" >> $filedat
    cat /proc/cpuinfo >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor ];
then
    echo "** CPU GOVERNOR:" >> $filedat
    ONLINECPUS=$(for CPU in $(find /sys/devices/system/cpu/ | grep cpu[0-9]*$); do [[ $(cat $CPU/online) -eq 1 ]] && echo $CPU; done | grep cpu[0-9]*$ | sed 's/.*cpu//')
    for PU in ${ONLINECPUS}; do
	     echo -n "CPU frequency for cpu${PU}: " >> $filedat
       cat /sys/devices/system/cpu/cpu${PU}/cpufreq/scaling_governor >> $filedat
    done
    echo "############################################" >> $filedat
fi

if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq ];
then
    echo "** CPU FREQUENCY:" >> $filedat
    ONLINECPUS=$(for CPU in $(find /sys/devices/system/cpu/ | grep cpu[0-9]*$); do [[ $(cat $CPU/online) -eq 1 ]] && echo $CPU; done | grep cpu[0-9]*$ | sed 's/.*cpu//')
    for PU in ${ONLINECPUS}; do
	     echo -n "CPU frequency for cpu${PU}: " >> $filedat
	     cat /sys/devices/system/cpu/cpu${PU}/cpufreq/scaling_cur_freq >> $filedat
    done
    echo "############################################" >> $filedat
fi

if [ -f /usr/bin/cpufreq-info ];
then
    echo "** CPUFREQ_INFO" >> $filedat
    cpufreq-info >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /usr/bin/lspci ];
then
    echo "** LSPCI" >> $filedat
    lspci >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /usr/bin/ompi_info ];
then
    echo "** OMPI_INFO" >> $filedat
    ompi_info --all >> $filedat
    echo "############################################" >> $filedat
fi

if [ -f /sbin/ifconfig ];
then
    echo "** IFCONFIG" >> $filedat
    /sbin/ifconfig >> $filedat
    echo "############################################" >> $filedat
fi

if [[ -n $(command -v nvidia-smi) ]];
then
    echo "** GPU INFO FROM NVIDIA-SMI:" >> $filedat
    nvidia-smi -q >> $filedat
    echo "############################################" >> $filedat
fi 

if [ -f /proc/version ];
then
    echo "** LINUX AND GCC VERSIONS:" >> $filedat
    cat /proc/version >> $filedat
    echo "############################################" >> $filedat
fi

if [[ -n $(command -v module) ]];
then
    echo "** MODULES:" >> $filedat
    module list 2>> $filedat
    echo "############################################" >> $filedat
fi

echo "** TCP PARAMETERS" >> $filedat
FILES="/proc/sys/net/core/rmem_max \
/proc/sys/net/core/wmem_max \
/proc/sys/net/core/rmem_default \
/proc/sys/net/core/wmem_default \
/proc/sys/net/core/netdev_max_backlog \
/proc/sys/net/ipv4/tcp_rmem \
/proc/sys/net/ipv4/tcp_wmem \
/proc/sys/net/ipv4/tcp_mem"

for FILE in $FILES; do
    echo "cat $FILE"
    cat $FILE
done >> $filedat

#+end_src

* Local Variables                                                  :noexport:
# Local Variables:
# eval: (ox-extras-activate '(ignore-headlines))
# eval: (setq org-latex-listings t)
# eval: (setq org-latex-packages-alist '(("" "listings")))
# eval: (setq org-latex-packages-alist '(("" "listingsutf8")))
# eval: (setq ispell-local-dictionary "brasileiro")
# eval: (flyspell-mode t)
# End:
