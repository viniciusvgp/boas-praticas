# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE:     Boas Práticas para Experimentos Computacionais em Clusters
#+SUBTITLE:  Tutorial Prático
#+AUTHOR:    Lucas Mello Schnorr, Vinícius Garcia Pinto
#+EMAIL:     {schnorr, vgpinto}@inf.ufrgs.br
#+DATE:      11 de abril de 2019

#+STARTUP: overview indent
#+LANGUAGE: pt_BR 
#+OPTIONS:   toc:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LATEX_HEADER: \usepackage[brazilian]{babel}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}

* Instalação de Ferramentas
#+BEGIN_COMMENT Vinicius
Dependências:
- git
- subversion (svn)
- openmpi
#+END_COMMENT

# Spack
Utilizaremos o gerenciador de pacotes ~Spack~ para obter, configurar,
compilar e instalar programas e bibliotecas sem permissões
especiais. Nesta seção, ilustraremos o funcionamento da ferramenta com
um pacote, um tutorial mais detalhado (em inglês) pode ser encontrado
em: https://spack.readthedocs.io/en/latest/tutorial.html.

Primeiramente, precisamos baixar o ~Spack~ a partir do repositório ~git~
oficial conforme instruções abaixo:
#+begin_src shell :results output :exports code :session S1 :eval no-export
git clone https://github.com/spack/spack.git
#+end_src

Com o ~Spack~ podemos instalar diversas ferramentas incluindo
compiladores. A lista de pacotes disponíveis pode ser obtida com o
comando ~spack list~. Por motivos de espaço, ilustramos abaixo como
listar os pacotes cujo nome inicia com =h=.

#+begin_src shell :results output :exports both :session S1 :eval no-export
cd spack
 ./bin/spack list h*
#+end_src

#+RESULTS:
#+begin_example

==> 50 packages.
h5hut    h5z-zfp      halc     haploview  hc    hdf5-blosc  hepmc    highfive     hisat2  homer       hpctoolkit  hpl   hsakmt  htslib  hugo      hybpiper  hyphy
h5part   hacckernels  hapcut2  harfbuzz   hdf   help2man    heppdt   highwayhash  hisea   hoomd-blue  hpcviewer   hpx   hstr    httpie  hunspell  hydra     hypre
h5utils  hadoop       hapdip   harminv    hdf5  henson      hic-pro  hiop         hmmer   hpccg       hpgmg       hpx5  htop    hub     hwloc     hydrogen

#+end_example

Neste tutorial instalaremos o pacote ~hwloc~. Este pacote permite obter
a topologia do ~hardware~ da plataforma e pode ser útil na identificação
dos /cores/ físicos e lógicos, dos nós NUMA, dos dispositivos PCI
conectados, da memória RAM entre outros. 

Instalaremos o ~hwloc~ na versão =2.0.2=, habilitando as opções ~pci~ e ~cairo~
e desabilitando as opções ~gl~ e ~cuda~.

#+begin_src shell :results output :exports code :eval no-export
./bin/spack install -v hwloc@2.0.2~gl+cairo~cuda+pci
#+end_src

Após a conclusão da instalação, podemos verificar os pacotes
instalados:
#+begin_src shell :results output :exports both :eval no-export
./bin/spack find
#+end_src

#+RESULTS:
#+begin_example

==> 34 installed packages
-- linux-debian-x86_64 / gcc@8.3.0 ------------------------------
bzip2@1.0.6    font-util@1.3.1    gettext@0.19.8.1  libbsd@0.9.1         libpng@1.6.34    m4@1.4.18       perl@5.26.2    readline@7.0        xz@5.2.4
cairo@1.16.0   fontconfig@2.12.3  glib@2.56.3       libffi@3.2.1         libsigsegv@2.11  ncurses@6.1     pixman@0.38.0  sqlite@3.26.0       zlib@1.2.11
diffutils@3.7  freetype@2.9.1     gperf@3.0.4       libiconv@1.15        libtool@2.4.6    openssl@1.1.1b  pkgconf@1.6.0  tar@1.31
expat@2.2.5    gdbm@1.18.1        hwloc@2.0.2       libpciaccess@0.13.5  libxml2@2.9.8    pcre@8.42       python@2.7.16  util-macros@1.19.1

#+end_example

Podemos notar que vários outros pacotes além do ~hwloc~ foram
instalados, estes pacotes foram instalados automaticamente pelo ~Spack~
pois são dependências necessárias para a compilação e/ou funcionamento
do ~hwloc~.

* Realização de Experimentos Computacionais
# Reserva de nós (SLURM)
# Coleta de dados (bash)
** Slurm
Neste tutorial usaremos o gerenciador de filas =Slurm=
[fn::https://slurm.schedmd.com]. O ~Slurm~ é uma ferramente /open-source/
que permite a execução de /jobs/ interativos ou não-interativos. 

O comando ~salloc~ abaixo exemplifica como poder ser realizada
solicitação de um /job/ interativo nomeado =MeuJobErad= na plataforma de
nome ~hype~, pelo período de 1 hora e 30 minutos.

#+begin_src shell :results output :exports both
salloc -p hype -J MeuJobErad -t 01:30:00
#+end_src

Quando a solicitação for atendida (o que pode ocorrer imediatamente
caso a plataforma esteja ociosa), o usuário estará apto a acessar a
máquina requisitada via ~ssh~ ou a executar diretamente sua aplicação
por meio do comando ~srun~.

Para /jobs/ não-interativos deve-se utilizar o comando ~sbatch~. Neste
caso, o usuário fornecerá um /script/ contendo todos os passos para
realizar o experimento na plataforma desejada. /Jobs/ não-interativos
são bastante úteis quando a plataforma é compartilhada entre muitos
usuários estando frequentemente ocupada e com uma significativa fila
de espera. Neste cenário, o /job/ do usuário poderá executar a qualquer
momento após a submissão, podendo ser iniciado em alguns segundos ou
até mesmo após vários dias da submissão. A política de filas não
necessariamente é /FIFO (First-In First-Out)/ pois alguns usuários
podem ter preferência sobre outros, por exemplo, contas internas /vs/
externas, preferência ao proprietário/financiador da plataforma,
preferência a equipe de manutenção/suporte, etc. 

Um ~job~ termina após uma das seguintes condições (a que occorer
primeiro): a execução da útlima linha do /script/ fornecido ou após o
término do tempo de processamento solicitado na reserva. Além destes
dois casos bases, o /job/ também pode ser encerrado por pedido do
usuário através do comando ~scancel~ ou por situações inesperadas como
problemas na plataforma ou comandos do administrador. 

O código abaixo ilustra um exemplo de /script/ a ser submetido com o
comando ~sbatch script-exemplo.sh~. Este /script/ exemplo solicita a
reserva de 2 nós na plataforma =hype= pelo período máximo de 40
minutos. As saídas padrão (/stdout/) e de erro (/stdin/) serão
redirecionadas para arquivos nomeados com o identificador do /job/.

#+begin_src shell :results output :exports both :tangle script-exemplo.sh :eval no-exoort

#!/bin/bash
#SBATCH --nodes=2
#SBATCH --partition=hype
#SBATCH --time=00:40:00
#SBATCH --output=%x_%j.out
#SBATCH --error=%x_%j.err

# Comandos para execução do experimento 

#+end_src

** Execução de uma aplicação paralelo exemplo
*** Obtenção e Configuração da Aplicação
Utilizaremos como exemplo a aplicação ~BT-MZ~ do conjunto de /benchmarks/
NPB[fn::https://www.nas.nasa.gov/publications/npb.html] (/NAS Parallel
Benchmarks/). A aplicação ~BT~ (/Block Tri-diagonal/) 

#+BEGIN_COMMENT Vinícius
Completar aqui com detalhes do BT em comparação com outros benchmarks
Explicar o MZ (multi-zone)
#+END_COMMENT


#+begin_src shell :results output :exports both :eval no-export
wget https://www.nas.nasa.gov/assets/npb/NPB3.4-MZ.tar.gz
tar -xf NPB3.4-MZ.tar.gz
cd NPB3.4-MZ/NPB3.4-MZ-MPI
cp config/NAS.samples/make.def.gcc_mpich config/make.def
make bt-mz CLASS=A
make bt-mz CLASS=W
#+end_src

#+RESULTS:

*** Projeto Experimental
<<sec:projexperimental>>
Após a instalação e configuração da aplicação, vamos utilizar o pacote
~DoE.base~ [fn::https://cran.r-project.org/web/packages/DoE.base/] da
linguagem ~R~ para gerar um projeto experimental combinando os fatores a
serem analisados. Neste exemplo, os fatores serão o número de /threads/,
o número de processos (/processes/) e a classe (/class/). As classes nos
/benchmarks/ NAS representam diferentes tamanhos de entrada do problema.

#+begin_src R :results output :exports both :session *R* :eval no-export
library("DoE.base")
library("dplyr")

btmz_erad <-
    fac.design(factor.names=
                   list(threads=c(1, 2), 
                        processes=c(1,2), 
                        class=c("W", "A")),
               replications=2, 
               randomize=TRUE
               )

print(btmz_erad)
#+end_src

#+RESULTS:
#+begin_example
creating full factorial with 8 runs ...
   run.no run.no.std.rp threads processes class Blocks
1       1           8.1       2         2     A     .1
2       2           2.1       2         1     W     .1
3       3           6.1       2         1     A     .1
4       4           4.1       2         2     W     .1
5       5           3.1       1         2     W     .1
6       6           1.1       1         1     W     .1
7       7           7.1       1         2     A     .1
8       8           5.1       1         1     A     .1
9       9           5.2       1         1     A     .2
10     10           3.2       1         2     W     .2
11     11           6.2       2         1     A     .2
12     12           4.2       2         2     W     .2
13     13           1.2       1         1     W     .2
14     14           7.2       1         2     A     .2
15     15           8.2       2         2     A     .2
16     16           2.2       2         1     W     .2
class=design, type= full factorial 
NOTE: columns run.no and run.no.std.rp  are annotation, 
 not part of the data frame
#+end_example

A função ~fac.design~ gerou uma sequência aleatorizada de combinações
que serão executadas para que possamos avaliar a influência de cada
fator no desempenho da aplicação. Exportaremos o projeto gerado para
um arquivo ~csv~ que deverá ser registrado juntamente com os /logs/
contendo os resultados brutos do experimento. 

#+begin_src R :results output :exports both :session *R* :eval no-export
export.design(btmz_erad, 
              filename = "btmz-exec-order",
              type = "csv",
              replace = TRUE
              )
#+end_src

#+RESULTS:

*** Execução dos Experimentos
Faremos a execução dos experimentos na ordem definida no projeto
experimental. 

#+begin_src shell :results output :exports code :eval no-export
tail -n +2 btmz-exec-order.csv |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 threads processes class Blocks
do
    # OpenMP threads
    runline="OMP_NUM_THREADS=$threads "
    # MPI processes
    runline+="mpirun -np $processes "
    # Binary
    runline+="bin/bt-mz.$class.x "
    # Log
    runline+="> btmz-$runno-$threads-$processes-$class.log"
 
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done 
#+end_src

*** Execução Não-Interativa de Experimentos com /Slurm/ na plataforma =PCAD=

Acessaremos a plataforma =PCAD= do GPPD/INF-UFRGS para execução de
experimentos de demonstração. Ilustraremos, no exemplo abaixo, um
/script/ para execução não-interativa da aplicação ~BT-MZ~ do pacote
NPB. Para efeitos de simplificação, foi gerado previamente um projeto
experimental (arquivo ~btmz-exec-order.csv~) considerando informações
sobre os recursos de processamento da plataforma obtidas com o
~hwloc~. Este projeto pode ser regerado com o código apresentado na
seção [[sec:projexperimental]].

#+begin_src shell :results output :exports both :tangle slurm-script.sh :eval no-export

#!/bin/bash

#SBATCH --nodes=2
#SBATCH --time=02:00:00
#SBATCH --partition=hype
#SBATCH --job-name=erad-2019-tutorial

# Working on scratch
cd $SCRATCH
mkdir erad-tuto
cd erad-tuto

# Spack and hwloc
git clone https://github.com/spack/spack.git
cd spack
./bin/spack install hwloc@2.0.2~gl+cairo~cuda+pci
cd ..

# Application
wget https://www.nas.nasa.gov/assets/npb/NPB3.4-MZ.tar.gz
tar -xf NPB3.4-MZ.tar.gz
cd NPB3.4-MZ/NPB3.4-MZ-MPI
cp config/NAS.samples/make.def.gcc_mpich config/make.def
make bt-mz CLASS=A
make bt-mz CLASS=W
cd ../..

# Experiments design (copy) 
cp ~/btmz-exec-order.csv ./

# MPI Machine file
MACHINEFILE="nodes.$SLURM_JOB_ID"
srun -l hostname | sort -n | awk '{print $2}' > $MACHINEFILE

tail -n +2 btmz-exec-order.csv |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 threads processes class Blocks
do
    # OpenMP threads
    runline="OMP_NUM_THREADS=$threads "
    # MPI processes
    runline+="mpirun -np $processes "
    # MPI machine file
    runline+=" -machinefile $MACHINEFILE "
    # Binary
    runline+="bin/bt-mz.$class.x "
    # Log
    runline+="> btmz-$runno-$threads-$processes-$class.log"
 
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done 
# Get info



#+end_src

* Análise de Dados
# R + tidyverse
Uma vez concluídas as execuções, inciaremos a etapa de análise dos
dados. A aplicação ~BT-MZ~ gera como saída arquivos texto no formato do
exemplo abaixo:

#+begin_src shell :results output :exports results
cat btmz-12-2-2-W.log
#+end_src

#+RESULTS:
#+begin_example


 NAS Parallel Benchmarks (NPB3.4-MZ MPI+OpenMP) - BT-MZ Benchmark

 Number of zones:   4 x   4
 Total mesh size:    64 x    64 x   8
 Iterations: 200    dt:   0.000800
 Number of active processes:      2

 Use the default load factors
 Total number of threads:      4  (  2.0 threads/process)

 Calculated speedup =      3.97

 Time step    1
 Time step   20
 Time step   40
 Time step   60
 Time step   80
 Time step  100
 Time step  120
 Time step  140
 Time step  160
 Time step  180
 Time step  200
 Verification being performed for class W
 accuracy setting for epsilon =  0.1000000000000E-07
 Comparison of RMS-norms of residual
           1 0.5562611195402E+05 0.5562611195402E+05 0.2275939447133E-13
           2 0.5151404119932E+04 0.5151404119932E+04 0.3177949982330E-13
           3 0.1080453907954E+05 0.1080453907954E+05 0.4318284922427E-12
           4 0.6576058591929E+04 0.6576058591929E+04 0.2074558846440E-13
           5 0.4528609293561E+05 0.4528609293561E+05 0.3100863263992E-13
 Comparison of RMS-norms of solution error
           1 0.7185154786403E+04 0.7185154786403E+04 0.4974582015591E-13
           2 0.7040472738068E+03 0.7040472738068E+03 0.3294113301485E-13
           3 0.1437035074443E+04 0.1437035074443E+04 0.1886032052721E-12
           4 0.8570666307849E+03 0.8570666307849E+03 0.3117191348368E-13
           5 0.5991235147368E+04 0.5991235147368E+04 0.6755287220979E-13
 Verification Successful


 BT-MZ Benchmark Completed.
 Class           =                        W
 Size            =             64x   64x  8
 Iterations      =                      200
 Time in seconds =                     2.28
 Total processes =                        2
 Total threads   =                        4
 Mop/s total     =                  6284.26
 Mop/s/thread    =                  1571.07
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      3.4
 Compile date    =              07 Apr 2019

 Compile options:
    FC           = mpif90
    FLINK        = $(FC)
    F_LIB        = (none)
    F_INC        = (none)
    FFLAGS       = -O3 -fopenmp
    FLINKFLAGS   = $(FFLAGS)
    RAND         = (none)


 Please send all errors/feedbacks to:

 NPB Development Team
 npb@nas.nasa.gov


#+end_example

Esta saída é bastante completa e contém varias informações como os
parâmetros utilizados na execução e as verificações de erro. Neste
tutorial, para efeitos de demonstração, estamos interessados apenas no
tempo de execução. Dessa forma, faremos uma limpeza nos arquivos de
~log~, de maneira a mantermos apenas a informação referente ao tempo de
execução.

#+begin_src shell :results output :exports code :eval no-export
for file in `find *.log`
do
    # sed -n '/seconds/p' $file | sed 's/.*=//' | sed -e 's/\s\+//g' > $file-time
    sed -n '/seconds/p' $file | sed 's/.*=//' > $file-time
done
#+end_src

#+RESULTS:

Após a limpeza, faremos uso da linguagem ~R~ para análise dos dados
observados nos experimentos. 

#+name: readingExpLogs
#+begin_src R :results output :exports both :session *R* :eval no-export
library(tidyverse)
library(dplyr)

options(crayon.enabled = FALSE)
options(pillar.sigfig=4)

expData <- 
    bind_rows(
        lapply(
            list.files(pattern = ".log-time"), 
            function(file){
                dt = 
                    read_csv(
                        file, 
                        trim_ws = TRUE, 
                        col_names = c("Time"), 
                        col_types = "d"
                    )
                dt$origin = 
                    sub('\\.log-time$', 
                        '', 
                        basename(file))
                dt %>% 
                    separate(origin, 
                             c("Application", 
                               "Run.No", 
                               "Threads", 
                               "Processes", 
                               "Class" ), 
                             sep = "-") %>%
                    select(Application, 
                           Run.No, 
                           Class, 
                           Processes, 
                           Threads, 
                           Time)
            }
        )
    ) 
expData
#+end_src

A partir de agora, podemos trabalhar somente na linguagem ~R~
diretamente com os dados que foram importados dos arquivos de ~log~ dos
experimentos. 

#+RESULTS: readingExpLogs
#+begin_example
# A tibble: 16 x 6
   Application Run.No Class Processes Threads   Time
   <chr>       <chr>  <chr> <chr>     <chr>    <dbl>
 1 btmz        1      A     2         2       20.45 
 2 btmz        10     W     2         1        3.35 
 3 btmz        11     A     1         2       23.18 
 4 btmz        12     W     2         2        2.280
 5 btmz        13     W     1         1        3.74 
 6 btmz        14     A     2         1       22.38 
 7 btmz        15     A     2         2       22.95 
 8 btmz        16     W     1         2        2.22 
 9 btmz        2      W     1         2        2.06 
10 btmz        3      A     1         2       26.04 
11 btmz        4      W     2         2        2.08 
12 btmz        5      W     2         1        2.030
13 btmz        6      W     1         1        3.75 
14 btmz        7      A     2         1       22.04 
15 btmz        8      A     1         1       40.36 
16 btmz        9      A     1         1       40.07
#+end_example

Como demonstração, faremos algumas computações estatísticas básicas
sobre os dados importados utilizando o pacote ~dplyr~ fornecido pelo
meta-pacote ~tidy-verse~.  As execuções serão agrupadas por Classe,
número de processos e número de /threads/, possibilitando que sejam
calculadas a média, a mediana, o valor mínimo e o valor máximo das
observações do tempo de execução da aplicação.

#+name: avg
#+begin_src R :results output :exports both :session *R* :eval no-export

expData %>% 
    group_by(Application, Class, Processes, Threads) %>% 
    summarize(Mean = mean(Time), 
              Median = median(Time), 
              Min = min(Time), 
              Max = max(Time))
#+end_src

#+RESULTS: avg
#+begin_example
# A tibble: 8 x 8
# Groups:   Application, Class, Processes [?]
  Application Class Processes Threads   Mean Median    Min    Max
  <chr>       <chr> <chr>     <chr>    <dbl>  <dbl>  <dbl>  <dbl>
1 btmz        A     1         1       40.22  40.22  40.07  40.36 
2 btmz        A     1         2       24.61  24.61  23.18  26.04 
3 btmz        A     2         1       22.21  22.21  22.04  22.38 
4 btmz        A     2         2       21.7   21.7   20.45  22.95 
5 btmz        W     1         1        3.745  3.745  3.74   3.75 
6 btmz        W     1         2        2.14   2.14   2.06   2.22 
7 btmz        W     2         1        2.69   2.69   2.030  3.35 
8 btmz        W     2         2        2.180  2.180  2.08   2.280
#+end_example

Podemos calcular também o /speed-up/ das execuções mais rápidas sobre a
mais lenta, e então ordenar as observações do menor para o maior
/speed-up/.

/Speed-up/ das execuções com a classe A:
#+name: speedup-A
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "A") %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 8 x 7
  Application Run.No Class Processes Threads  Time SpeedUp
  <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
1 btmz        8      A     1         1       40.36   1    
2 btmz        9      A     1         1       40.07   1.007
3 btmz        3      A     1         2       26.04   1.550
4 btmz        11     A     1         2       23.18   1.741
5 btmz        15     A     2         2       22.95   1.759
6 btmz        14     A     2         1       22.38   1.803
7 btmz        7      A     2         1       22.04   1.831
8 btmz        1      A     2         2       20.45   1.974
#+end_example

/Speed-up/ das execuções com a classe W:
#+name: speedup-W
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "W") %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS: speedup-W
#+begin_example
# A tibble: 8 x 7
  Application Run.No Class Processes Threads  Time SpeedUp
  <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
1 btmz        6      W     1         1       3.75    1    
2 btmz        13     W     1         1       3.74    1.003
3 btmz        10     W     2         1       3.35    1.119
4 btmz        12     W     2         2       2.280   1.645
5 btmz        16     W     1         2       2.22    1.689
6 btmz        4      W     2         2       2.08    1.803
7 btmz        2      W     1         2       2.06    1.820
8 btmz        5      W     2         1       2.030   1.847
#+end_example

Podemos ainda verificar o /speed-up/ quando variamos apenas o número de
/threads/,

Classe A:
#+name: speedup-A-P1
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "A", Processes == 1) %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS: speedup-A-P1
: # A tibble: 4 x 7
:   Application Run.No Class Processes Threads  Time SpeedUp
:   <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
: 1 btmz        8      A     1         1       40.36   1    
: 2 btmz        9      A     1         1       40.07   1.007
: 3 btmz        3      A     1         2       26.04   1.550
: 4 btmz        11     A     1         2       23.18   1.741

ou quando variamos apenas o número de processos.

Classe A:
#+name: speedup-A-T1
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "A", Threads == 1) %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS: speedup-A-T1
: # A tibble: 4 x 7
:   Application Run.No Class Processes Threads  Time SpeedUp
:   <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
: 1 btmz        8      A     1         1       40.36   1    
: 2 btmz        9      A     1         1       40.07   1.007
: 3 btmz        14     A     2         1       22.38   1.803
: 4 btmz        7      A     2         1       22.04   1.831


* Criação de Gráficos
# ggplot2
Além da computação de medidas estatísticas, a linguagem ~R~ também pode
ser usada para criação de gráficos. O pacote ~ggplot2~ implementa uma
gramática de gráficos, o que permite gerar gráficos claros e
expressivos. A Figura [[lfig:tempo]] mostra um gráfico simples onde cada
execução é representada por um ponto. Cores foram adicionadas para
separar as duas classes. 


#+name: fig:tempo
#+begin_src R :results output graphics :file figtempo.png :exports both :width 600 :height 400 :session *R*  :eval no-export
library(ggplot2)

expData %>% 
    mutate(X = paste0(Threads, "x", Processes)) %>%
    ggplot(aes(y = Time, x = X, color = Class)) +
    geom_point() +
    theme_bw() +
    xlab("Threads x Processes")  +
    ggtitle("NPB BT-MZ Execution Time")

#+end_src

#+LABEL: lfig:tempo
#+RESULTS: fig:tempo
[[file:figtempo.png]]


Gráficos como o da Figura [[lfig:tempo]] que apresentam valores com grande
variação tendem a ocultar informações. No caso da aplicação ~BT-MZ~, o
tempo de execução maior da classe A esconde detalhes das execuções da
classe W devido a escala necessária para exibir os valores da
primeira. O pacote ~ggplot~ permite contornar este tipo de problema por
meio do uso de ~facets~ conforme ilustrado na Figura [[lfig:tempofacet]].

#+name: fig:tempofacet
#+begin_src R :results output graphics :file figtempo-facet.png :exports both :width 600 :height 400 :session *R*  :eval no-export
library(ggplot2)

expData %>% 
    mutate(X = paste0(Threads, "x", Processes)) %>%
    ggplot(aes(y = Time, x = X, color = Class)) +
    geom_point() +
    facet_grid(Class~., scales="free_y") + 
    theme_bw() +
    xlab("Threads x Processes") +
    ggtitle("NPB BT-MZ Execution Time")
   
#+end_src

#+LABEL: lfig:tempofacet
#+RESULTS: fig:tempofacet
[[file:figtempo-facet.png]]


* Local Variables                                                  :noexport:
# Local Variables:
# eval: (ox-extras-activate '(ignore-headlines))
# eval: (setq org-latex-listings t)
# eval: (setq org-latex-packages-alist '(("" "listings")))
# eval: (setq org-latex-packages-alist '(("" "listingsutf8")))
# eval: (setq ispell-local-dictionary "brasileiro")
# eval: (flyspell-mode t)
# End:

* Dockerfile                                                       :noexport:
#+begin_src fundamental :tangle tmp/Dockerfile
FROM r-base:3.5.1

RUN apt update && apt -y upgrade
RUN apt -y install libxml2-dev libssl-dev libcurl4-openssl-dev libgit2-dev
RUN apt -y install libboost-dev 

# Spack
RUN apt -y install git python curl autoconf file

# DoE.base
RUN apt -y install libgmp-dev

# MPI
RUN apt -y install libopenmpi-dev

# R packages
RUN echo "install.packages(c('tidyverse', 'devtools', 'DoE.base'), repos = 'http://cran.us.r-project.org')" | R --vanilla

RUN useradd -s /bin/bash --create-home user
USER user

ENTRYPOINT /bin/bash
WORKDIR /home/user
#+end_src
