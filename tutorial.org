# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+TITLE:     Boas Práticas para Experimentos Computacionais em Clusters
#+SUBTITLE:  Tutorial Prático
#+AUTHOR:    Lucas Mello Schnorr, Vinícius Garcia Pinto
#+EMAIL:     {schnorr, vgpinto}@inf.ufrgs.br
#+DATE:      11 de abril de 2019

#+STARTUP: overview indent
#+LANGUAGE: pt_BR 
#+OPTIONS:   toc:nil
#+TAGS: noexport(n) deprecated(d) ignore(i)
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport

#+LATEX_HEADER: \usepackage[brazilian]{babel}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}

* Instalação de Ferramentas
#+BEGIN_COMMENT Vinicius
Dependências:
- git
- subversion (svn)
- openmpi
#+END_COMMENT

# Spack
Utilizaremos o gerenciador de pacotes ~Spack~ para obter, configurar,
compilar e instalar programas e bibliotecas sem permissões
especiais. Nesta seção, ilustraremos o funcionamento da ferramenta com
um pacote, um tutorial mais detalhado (em inglês) pode ser encontrado
em: https://spack.readthedocs.io/en/latest/tutorial.html.

Primeiramente, precisamos baixar o ~Spack~ a partir do repositório ~git~
oficial conforme instruções abaixo:
#+begin_src shell :results output :exports code :session S1 :eval no-export
git clone https://github.com/spack/spack.git
#+end_src

Com o ~Spack~ podemos instalar diversas ferramentas incluindo
compiladores. A lista de pacotes disponíveis pode ser obtida com o
comando ~spack list~. Por motivos de espaço, ilustramos abaixo como
listar os pacotes cujo nome inicia com =h=.

#+begin_src shell :results output :exports both :session S1 :eval no-export
cd spack
 ./bin/spack list h*
#+end_src

#+RESULTS:
#+begin_example

==> 50 packages.
h5hut    h5z-zfp      halc     haploview  hc    hdf5-blosc  hepmc    highfive     hisat2  homer       hpctoolkit  hpl   hsakmt  htslib  hugo      hybpiper  hyphy
h5part   hacckernels  hapcut2  harfbuzz   hdf   help2man    heppdt   highwayhash  hisea   hoomd-blue  hpcviewer   hpx   hstr    httpie  hunspell  hydra     hypre
h5utils  hadoop       hapdip   harminv    hdf5  henson      hic-pro  hiop         hmmer   hpccg       hpgmg       hpx5  htop    hub     hwloc     hydrogen

#+end_example

Neste tutorial instalaremos o pacote ~hwloc~. Este pacote permite obter
a topologia do ~hardware~ da plataforma e pode ser útil na identificação
dos /cores/ físicos e lógicos, dos nós NUMA, dos dispositivos PCI
conectados, da memória RAM entre outros. 

Instalaremos o ~hwloc~ na versão =2.0.2=, habilitando as opções ~pci~ e ~cairo~
e desabilitando as opções ~gl~ e ~cuda~.

#+begin_src shell :results output :exports code :eval no-export
./bin/spack install -v hwloc@2.0.2~gl+cairo~cuda+pci
#+end_src

Após a conclusão da instalação, podemos verificar os pacotes
instalados:
#+begin_src shell :results output :exports both :eval no-export
./bin/spack find
#+end_src

Podemos notar que vários outros pacotes além do ~hwloc~ foram
instalados, estes pacotes foram instalados automaticamente pelo ~Spack~
pois são dependências necessárias para a compilação e/ou funcionamento
do ~hwloc~.

* Realização de Experimentos Computacionais
# Reserva de nós (SLURM)
# Coleta de dados (bash)
** Execução de uma aplicação paralelo exemplo
*** Obtenção e Configuração da Aplicação
Utilizaremos como exemplo a aplicação ~BT-MZ~ do conjunto de /benchmarks/
NPB[fn::https://www.nas.nasa.gov/publications/npb.html] (/NAS Parallel
Benchmarks/). A aplicação ~BT~ (/Block Tri-diagonal/) 

#+BEGIN_COMMENT Vinícius
Completar aqui com detalhes do BT em comparação com outros benchmarks
Explicar o MZ (multi-zone)
#+END_COMMENT


#+begin_src shell :results output :exports both :eval no-export
wget https://www.nas.nasa.gov/assets/npb/NPB3.4-MZ.tar.gz
tar -xf NPB3.4-MZ.tar.gz
cd NPB3.4-MZ/NPB3.4-MZ-MPI
cp config/NAS.samples/make.def.gcc_mpich config/make.def
make bt-mz CLASS=A
make bt-mz CLASS=W
#+end_src

#+RESULTS:

*** Projeto Experimental
Após a instalação e configuração da aplicação, vamos utilizar o pacote
~DoE.base~ [fn::https://cran.r-project.org/web/packages/DoE.base/] da
linguagem ~R~ para gerar um projeto experimental combinando os fatores a
serem analisados. Neste exemplo, os fatores serão o número de /threads/,
o número de processos (/processes/) e a classe (/class/). As classes nos
/benchmarks/ NAS representam diferentes tamanhos de entrada do problema.

#+begin_src R :results output :exports both :session *R* :eval no-export
library("DoE.base")
library("dplyr")

btmz_erad <-
    fac.design(factor.names=
                   list(threads=c(1, 2), 
                        processes=c(1,2), 
                        class=c("W", "A")),
               replications=2, 
               randomize=TRUE
               )

print(btmz_erad)
#+end_src

#+RESULTS:
#+begin_example
creating full factorial with 8 runs ...
   run.no run.no.std.rp threads processes class Blocks
1       1           8.1       2         2     A     .1
2       2           2.1       2         1     W     .1
3       3           6.1       2         1     A     .1
4       4           4.1       2         2     W     .1
5       5           3.1       1         2     W     .1
6       6           1.1       1         1     W     .1
7       7           7.1       1         2     A     .1
8       8           5.1       1         1     A     .1
9       9           5.2       1         1     A     .2
10     10           3.2       1         2     W     .2
11     11           6.2       2         1     A     .2
12     12           4.2       2         2     W     .2
13     13           1.2       1         1     W     .2
14     14           7.2       1         2     A     .2
15     15           8.2       2         2     A     .2
16     16           2.2       2         1     W     .2
class=design, type= full factorial 
NOTE: columns run.no and run.no.std.rp  are annotation, 
 not part of the data frame
#+end_example

A função ~fac.design~ gerou uma sequência aleatorizada de combinações
que serão executadas para que possamos avaliar a influência de cada
fator no desempenho da aplicação. Exportaremos o projeto gerado para
um arquivo ~csv~ que deverá ser registrado juntamente com os /logs/
contendo os resultados brutos do experimento. 

#+begin_src R :results output :exports both :session *R* :eval no-export
export.design(btmz_erad, 
              filename = "btmz-exec-order",
              type = "csv",
              replace = TRUE
              )
#+end_src

#+RESULTS:

*** Execução dos Experimentos
Faremos a execução dos experimentos na ordem definida no projeto
experimental. 

#+begin_src shell :results output :exports code :eval no-export
tail -n +2 btmz-exec-order.csv |
while IFS=, read -r name runnoinstdorder runno runnostdrp \
	 threads processes class Blocks
do
    # OpenMP threads
    runline="OMP_NUM_THREADS=$threads "
    # MPI processes
    runline+="mpirun -np $processes "
    # Binary
    runline+="bin/bt-mz.$class.x "
    # Log
    runline+="> btmz-$runno-$threads-$processes-$class.log"
 
    echo "Running >> $runline <<"
    eval "$runline < /dev/null"
    echo "Done!"
done 
#+end_src

* Análise de Dados
# R + tidyverse
Uma vez concluídas as execuções, inciaremos a etapa de análise dos
dados. A aplicação ~BT-MZ~ gera como saída arquivos texto no formato do
exemplo abaixo:

#+begin_src shell :results output :exports results
cat btmz-12-2-2-W.log
#+end_src

#+RESULTS:
#+begin_example


 NAS Parallel Benchmarks (NPB3.4-MZ MPI+OpenMP) - BT-MZ Benchmark

 Number of zones:   4 x   4
 Total mesh size:    64 x    64 x   8
 Iterations: 200    dt:   0.000800
 Number of active processes:      2

 Use the default load factors
 Total number of threads:      4  (  2.0 threads/process)

 Calculated speedup =      3.97

 Time step    1
 Time step   20
 Time step   40
 Time step   60
 Time step   80
 Time step  100
 Time step  120
 Time step  140
 Time step  160
 Time step  180
 Time step  200
 Verification being performed for class W
 accuracy setting for epsilon =  0.1000000000000E-07
 Comparison of RMS-norms of residual
           1 0.5562611195402E+05 0.5562611195402E+05 0.2275939447133E-13
           2 0.5151404119932E+04 0.5151404119932E+04 0.3177949982330E-13
           3 0.1080453907954E+05 0.1080453907954E+05 0.4318284922427E-12
           4 0.6576058591929E+04 0.6576058591929E+04 0.2074558846440E-13
           5 0.4528609293561E+05 0.4528609293561E+05 0.3100863263992E-13
 Comparison of RMS-norms of solution error
           1 0.7185154786403E+04 0.7185154786403E+04 0.4974582015591E-13
           2 0.7040472738068E+03 0.7040472738068E+03 0.3294113301485E-13
           3 0.1437035074443E+04 0.1437035074443E+04 0.1886032052721E-12
           4 0.8570666307849E+03 0.8570666307849E+03 0.3117191348368E-13
           5 0.5991235147368E+04 0.5991235147368E+04 0.6755287220979E-13
 Verification Successful


 BT-MZ Benchmark Completed.
 Class           =                        W
 Size            =             64x   64x  8
 Iterations      =                      200
 Time in seconds =                     2.28
 Total processes =                        2
 Total threads   =                        4
 Mop/s total     =                  6284.26
 Mop/s/thread    =                  1571.07
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      3.4
 Compile date    =              07 Apr 2019

 Compile options:
    FC           = mpif90
    FLINK        = $(FC)
    F_LIB        = (none)
    F_INC        = (none)
    FFLAGS       = -O3 -fopenmp
    FLINKFLAGS   = $(FFLAGS)
    RAND         = (none)


 Please send all errors/feedbacks to:

 NPB Development Team
 npb@nas.nasa.gov


#+end_example

Esta saída é bastante completa e contém varias informações como os
parâmetros utilizados na execução e as verificações de erro. Neste
tutorial, para efeitos de demonstração, estamos interessados apenas no
tempo de execução. Dessa forma, faremos uma limpeza nos arquivos de
~log~, de maneira a mantermos apenas a informação referente ao tempo de
execução.

#+begin_src shell :results output :exports code :eval no-export
for file in `find *.log`
do
    # sed -n '/seconds/p' $file | sed 's/.*=//' | sed -e 's/\s\+//g' > $file-time
    sed -n '/seconds/p' $file | sed 's/.*=//' > $file-time
done
#+end_src

#+RESULTS:

Após a limpeza, faremos uso da linguagem ~R~ para análise dos dados
observados nos experimentos. 

#+name: readingExpLogs
#+begin_src R :results output :exports both :session *R* :eval no-export
library(tidyverse)
library(dplyr)

options(crayon.enabled = FALSE)
options(pillar.sigfig=4)

expData <- 
    bind_rows(
        lapply(
            list.files(pattern = ".log-time"), 
            function(file){
                dt = 
                    read_csv(
                        file, 
                        trim_ws = TRUE, 
                        col_names = c("Time"), 
                        col_types = "d"
                    )
                dt$origin = 
                    sub('\\.log-time$', 
                        '', 
                        basename(file))
                dt %>% 
                    separate(origin, 
                             c("Application", 
                               "Run.No", 
                               "Threads", 
                               "Processes", 
                               "Class" ), 
                             sep = "-") %>%
                    select(Application, 
                           Run.No, 
                           Class, 
                           Processes, 
                           Threads, 
                           Time)
            }
        )
    ) 
expData
#+end_src

A partir de agora, podemos trabalhar somente na linguagem ~R~
diretamente com os dados que foram importados dos arquivos de ~log~ dos
experimentos. 

#+RESULTS: readingExpLogs
#+begin_example
# A tibble: 16 x 6
   Application Run.No Class Processes Threads   Time
   <chr>       <chr>  <chr> <chr>     <chr>    <dbl>
 1 btmz        1      A     2         2       20.45 
 2 btmz        10     W     2         1        3.35 
 3 btmz        11     A     1         2       23.18 
 4 btmz        12     W     2         2        2.280
 5 btmz        13     W     1         1        3.74 
 6 btmz        14     A     2         1       22.38 
 7 btmz        15     A     2         2       22.95 
 8 btmz        16     W     1         2        2.22 
 9 btmz        2      W     1         2        2.06 
10 btmz        3      A     1         2       26.04 
11 btmz        4      W     2         2        2.08 
12 btmz        5      W     2         1        2.030
13 btmz        6      W     1         1        3.75 
14 btmz        7      A     2         1       22.04 
15 btmz        8      A     1         1       40.36 
16 btmz        9      A     1         1       40.07
#+end_example

Como demonstração, faremos algumas computações estatísticas básicas
sobre os dados importados utilizando o pacote ~dplyr~ fornecido pelo
meta-pacote ~tidy-verse~.  As execuções serão agrupadas por Classe,
número de processos e número de /threads/, possibilitando que sejam
calculadas a média, a mediana, o valor mínimo e o valor máximo das
observações do tempo de execução da aplicação.

#+name: avg
#+begin_src R :results output :exports both :session *R* :eval no-export

expData %>% 
    group_by(Application, Class, Processes, Threads) %>% 
    summarize(Mean = mean(Time), 
              Median = median(Time), 
              Min = min(Time), 
              Max = max(Time))
#+end_src

#+RESULTS: avg
#+begin_example
# A tibble: 8 x 8
# Groups:   Application, Class, Processes [?]
  Application Class Processes Threads   Mean Median    Min    Max
  <chr>       <chr> <chr>     <chr>    <dbl>  <dbl>  <dbl>  <dbl>
1 btmz        A     1         1       40.22  40.22  40.07  40.36 
2 btmz        A     1         2       24.61  24.61  23.18  26.04 
3 btmz        A     2         1       22.21  22.21  22.04  22.38 
4 btmz        A     2         2       21.7   21.7   20.45  22.95 
5 btmz        W     1         1        3.745  3.745  3.74   3.75 
6 btmz        W     1         2        2.14   2.14   2.06   2.22 
7 btmz        W     2         1        2.69   2.69   2.030  3.35 
8 btmz        W     2         2        2.180  2.180  2.08   2.280
#+end_example

Podemos calcular também o /speed-up/ das execuções mais rápidas sobre a
mais lenta, e então ordenar as observações do menor para o maior
/speed-up/.

/Speed-up/ das execuções com a classe A:
#+name: speedup-A
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "A") %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS:
#+begin_example
# A tibble: 8 x 7
  Application Run.No Class Processes Threads  Time SpeedUp
  <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
1 btmz        8      A     1         1       40.36   1    
2 btmz        9      A     1         1       40.07   1.007
3 btmz        3      A     1         2       26.04   1.550
4 btmz        11     A     1         2       23.18   1.741
5 btmz        15     A     2         2       22.95   1.759
6 btmz        14     A     2         1       22.38   1.803
7 btmz        7      A     2         1       22.04   1.831
8 btmz        1      A     2         2       20.45   1.974
#+end_example

/Speed-up/ das execuções com a classe W:
#+name: speedup-W
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "W") %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS: speedup-W
#+begin_example
# A tibble: 8 x 7
  Application Run.No Class Processes Threads  Time SpeedUp
  <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
1 btmz        6      W     1         1       3.75    1    
2 btmz        13     W     1         1       3.74    1.003
3 btmz        10     W     2         1       3.35    1.119
4 btmz        12     W     2         2       2.280   1.645
5 btmz        16     W     1         2       2.22    1.689
6 btmz        4      W     2         2       2.08    1.803
7 btmz        2      W     1         2       2.06    1.820
8 btmz        5      W     2         1       2.030   1.847
#+end_example

Podemos ainda verificar o /speed-up/ quando variamos apenas o número de
/threads/,

Classe A:
#+name: speedup-A-P1
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "A", Processes == 1) %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS: speedup-A-P1
: # A tibble: 4 x 7
:   Application Run.No Class Processes Threads  Time SpeedUp
:   <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
: 1 btmz        8      A     1         1       40.36   1    
: 2 btmz        9      A     1         1       40.07   1.007
: 3 btmz        3      A     1         2       26.04   1.550
: 4 btmz        11     A     1         2       23.18   1.741

ou quando variamos apenas o número de processos.

Classe A:
#+name: speedup-A-T1
#+begin_src R :results output :exports both :session *R* :eval no-export
expData %>% 
    filter(Class == "A", Threads == 1) %>%
    mutate(SpeedUp = max(Time)/Time) %>% 
    arrange(SpeedUp)
#+end_src

#+RESULTS: speedup-A-T1
: # A tibble: 4 x 7
:   Application Run.No Class Processes Threads  Time SpeedUp
:   <chr>       <chr>  <chr> <chr>     <chr>   <dbl>   <dbl>
: 1 btmz        8      A     1         1       40.36   1    
: 2 btmz        9      A     1         1       40.07   1.007
: 3 btmz        14     A     2         1       22.38   1.803
: 4 btmz        7      A     2         1       22.04   1.831


* Criação de Gráficos
# ggplot2

* Local Variables                                                  :noexport:
# Local Variables:
# eval: (ox-extras-activate '(ignore-headlines))
# eval: (setq org-latex-listings t)
# eval: (setq org-latex-packages-alist '(("" "listings")))
# eval: (setq org-latex-packages-alist '(("" "listingsutf8")))
# eval: (setq ispell-local-dictionary "brasileiro")
# eval: (flyspell-mode t)
# End:

* Dockerfile                                                       :noexport:
#+begin_src fundamental :tangle tmp/Dockerfile
FROM r-base:3.5.1

RUN apt update && apt -y upgrade
RUN apt -y install libxml2-dev libssl-dev libcurl4-openssl-dev libgit2-dev
RUN apt -y install libboost-dev 

# Spack
RUN apt -y install git python curl autoconf file

# DoE.base
RUN apt -y install libgmp-dev

# MPI
RUN apt -y install libopenmpi-dev

# R packages
RUN echo "install.packages(c('tidyverse', 'devtools', 'DoE.base'), repos = 'http://cran.us.r-project.org')" | R --vanilla

RUN useradd -s /bin/bash --create-home user
USER user

ENTRYPOINT /bin/bash
WORKDIR /home/user
#+end_src
